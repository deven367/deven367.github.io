---
title: Emergence of Episodic Memory in Transformers - Characterizing Changes in Temporal Structure of Attention Scores During Training
type: "article"
publication: "arXiv Preprint"
year: 2025
author: Mistry, Deven Mahesh; Bajaj, Anooshka; Aggarwal, Yash; Maini, Sahaj Singh; Tiganj, Zoran
preprint: "https://arxiv.org/abs/2502.06902"
doi: "https://doi.org/10.48550/arXiv.2502.06902"
toc: false
categories:
  - language models
  - episodic memory
  - free recall
---
## Citation (APA 7)

> Mistry, D. M., Bajaj, A., Aggarwal, Y., Maini, S. S., & Tiganj, Z. (2025). Emergence of Episodic Memory in Transformers: Characterizing Changes in Temporal Structure of Attention Scores During Training. arXiv preprint arXiv:2502.06902.

## Abstract

We investigate in-context temporal biases in attention heads and transformer outputs. Using cognitive science methodologies, we analyze attention scores and outputs of the GPT-2 models of varying sizes. Across attention heads, we observe effects characteristic of human episodic memory, including temporal contiguity, primacy and recency. Transformer outputs demonstrate a tendency toward in-context serial recall. Importantly, this effect is eliminated after the ablation of the induction heads, which are the driving force behind the contiguity effect. Our findings offer insights into how transformers organize information temporally during in-context learning, shedding light on their similarities and differences with human memory and learning.